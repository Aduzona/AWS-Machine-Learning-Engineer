{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning a CNN in Pytorch\n",
    "\n",
    "Here are the steps you need to do to finetune a CNN in PyTorch\n",
    "\n",
    "1. To finetune a CNN, we first need to select a pre-trained model. Pytorch already has a few pre-trained models available and to access them, you need to first import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, we need to create our model. When creating our model we need to freeze all the convolutional layers which we do by their `requires_grad()` attribute to `False`. We also need to add a fully connected layer on top of it which we do use the Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False# means freeze convolutional layer   \n",
    "\n",
    "    num_features=model.fc.in_features#number of features \n",
    "    model.fc = nn.Sequential(\n",
    "                   nn.Linear(num_features, 10))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training our model will go faster if we use the GPU. We first check if GPU is available by checking for `cuda` devices. To use the GPU we need to put the model on the GPU device by using the `to()` method of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on Device {device}\")\n",
    "\n",
    "model=create_model()\n",
    "model=model.to(device)# Activates GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Finally, we can create our training loop. This loop remains the same as before, except that we need to put our data on the GPU device as well by using the same `to()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, cost, optimizer, epoch):\n",
    " model.train()\n",
    " for e in range(epoch):\n",
    "     running_loss=0\n",
    "     correct=0\n",
    "     for data, target in train_loader:\n",
    "         data=data.to(device)\n",
    "         target=target.to(device)\n",
    "         optimizer.zero_grad()\n",
    "         pred = model(data)             #No need to reshape data since CNNs take image inputs\n",
    "         loss = cost(pred, target)\n",
    "         running_loss+=loss\n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "         pred=pred.argmax(dim=1, keepdim=True)\n",
    "         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "     print(f\"Epoch {e}: Loss {running_loss/len(train_loader.dataset)}, \\\n",
    "         Accuracy {100*(correct/len(train_loader.dataset))}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "066f0cf44a99ba1e11fccf4678337f6c13d471cb9e5f054ce5432a88f7410f59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
